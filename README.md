# VDPA: Variance-driven Dual-Path Attention (Official PyTorch)

> STK (Soft Top-K) Â· LGA (Learnable Global Attention) Â· VDFC (Variance-Driven Fusion Controller) Â· ALP (Adaptive Local Pooling, dynamic class token)

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![PyTorch â‰¥1.10](https://img.shields.io/badge/PyTorch-%E2%89%A51.10-ee4c2c?logo=pytorch&logoColor=white)](https://pytorch.org/)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-3776ab?logo=python&logoColor=white)](https://www.python.org/downloads/)

æœ¬ä»“åº“åŒ…å« **VDPA æ¨¡å‹æœ€å°å¯å¤ç°å®ç°** ä¸ **ç»Ÿä¸€æ•ˆç‡ / å‚æ•°é‡ / FLOPs åŸºå‡†è„šæœ¬**ã€‚  
This repo provides a minimal VDPA implementation plus unified efficiency/params/FLOPs benchmarks.

---

## ğŸ§­ ç›®å½•
- [Highlights](#-highlights)
- [å®‰è£…](#-å®‰è£…)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [ç»Ÿä¸€æ•ˆç‡åŸºå‡†](#-ç»Ÿä¸€æ•ˆç‡åŸºå‡†)
- [ä¾èµ–](#-ä¾èµ–)
- [è®¸å¯](#-è®¸å¯)
- [å¼•ç”¨](#-å¼•ç”¨)
- [è‡´è°¢](#-è‡´è°¢)

---

## âœ¨ Highlights
- **åŒåˆ†æ”¯æ³¨æ„åŠ›**ï¼šSTKï¼ˆè½¯åŒ–çš„ Top-K ç¨€ç–å±€éƒ¨ï¼‰ Ã— LGAï¼ˆå¯å­¦ä¹ å…¨å±€èšåˆï¼‰ã€‚
- **æ ·æœ¬çº§èåˆé—¨æ§**ï¼šVDFC ä»¥ token æ–¹å·®ä½œä¸ºç»“æ„ç¦»æ•£åº¦ä¿¡å·ï¼Œè‡ªé€‚åº”è°ƒèŠ‚å±€éƒ¨/å…¨å±€æ¯”ä¾‹ã€‚
- **åŠ¨æ€ç±»æ ‡æ„é€ **ï¼šALP åŸºäºé‚»åŸŸä½™å¼¦æƒé‡èšåˆï¼Œç”Ÿæˆä¸å¼•å…¥é¢å¤– [CLS] çš„ class tokenã€‚
- **æ•´æ´å®ç°**ï¼šçº¯ PyTorchã€ä¾èµ–æœ€å°ï¼›é…å¥— `timm` ä¸ VMamba ç­‰åŸºçº¿çš„ç»Ÿä¸€åŸºå‡†è„šæœ¬ã€‚

---

## ğŸ“¦ å®‰è£…

**æ–¹å¼ Aï½œpipï¼ˆè½»é‡ï¼‰**
```bash
pip install -r requirements.txt


---

## ğŸš€ å¿«é€Ÿå¼€å§‹
import torch
from vdpapkg.models.vdpa import VDPA

model = VDPA(num_classes=2, depth=10, embed_dim=512, num_heads=8)
x = torch.randn(1, 3, 512, 512)
logits = model(x)
print(logits.shape)  # [1, 2]

## ğŸ§ª ç»Ÿä¸€æ•ˆç‡åŸºå‡†

è„šæœ¬ä¸€ï½œmeasure_modelsï¼ˆå¯¼å‡º CSVï¼Œå« timm / VMamba åŸºçº¿ï¼‰

python benchmarks/measure_models.py \
  --models vdpa,convnextv2_tiny,maxvit,vmamba_tiny \
  --img 512 --bs 1 --embed 512 --depth 10 --heads 8 \
  --fp16 --threads 8 --csv results_efficiency.csv


è„šæœ¬äºŒï½œbench_models_baseï¼ˆâ€œBase/å¤§æ¯â€ä½“é‡æ˜ å°„ + VDPAï¼‰

python benchmarks/bench_models_base.py \
  --models resnet50,vit,swin-transformer,vdpa \
  --img 512 --bs 1 --fp16

## ğŸ”§ ä¾èµ–

Python â‰¥ 3.8

PyTorch â‰¥ 1.10

ï¼ˆå¯é€‰ï¼‰timmã€ptflops / thop / fvcoreã€numpy

## ğŸ“„ è®¸å¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ï¼ˆè§ LICENSE
ï¼‰ã€‚

## ğŸ”— å¼•ç”¨

å¦‚æœæœ¬é¡¹ç›®å¯¹ä½ çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·åœ¨è®ºæ–‡æˆ–é¡¹ç›®ä¸­å¼•ç”¨ï¼ˆè§ CITATION.cffï¼‰ã€‚

ğŸ™ è‡´è°¢

timmã€fvcoreã€ptflopsã€thop ç­‰ä¼˜ç§€å¼€æºé¡¹ç›®ã€‚
